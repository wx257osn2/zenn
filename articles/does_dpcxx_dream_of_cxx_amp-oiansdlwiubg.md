---
title: "DPC++ã¯C++ AMPã®å¤¢ã‚’è¦‹ã‚‹ã‹"
emoji: "ğŸ†‘"
type: "tech"
topics: ["cpp", "opencl"]
published: true
---

[C++ Advent Calendar 2022](https://qiita.com/advent-calendar/2022/cxx)ç„¡äº‹^[[ä¸»å‚¬ã®ãã›ã«9æ—¥è¿‘ãé…åˆ»ã—ãŸã‚„ã¤](https://twitter.com/wx257osn2)ãŒã„ã‚‹ã®ã§ç„¡äº‹ã¨å‘¼ã¹ã‚‹ã‹ã¯æ€ªã—ã„]å®Œèµ°ã—ã¾ã—ãŸï¼çš†æ§˜ä»Šå¹´ã‚‚ã”å‚åŠ ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼
æœ¬ç¨¿ã¯ï¼ŒC++ AdC 2022 20æ—¥ç›®ã®è¨˜äº‹ã§ã‚„ã‚ã†ã¨æ€ã£ãŸãŒ[èª¿æŸ»ã®çµæœã‚„ã‚ŠãŸã„ã“ã¨ãŒã§ãã‚“ã“ã¨ãŒã‚ã‹ã‚Šï¼Œè«¦ã‚ãŸ](https://twitter.com/wx257osn2/status/1606716867468742656)æ²¡ãƒã‚¿ã«ã¤ã„ã¦ã®è¨˜äº‹ã§ã™^[æ‰€è©®æ²¡ã®è¨˜äº‹ãªã®ã§çµæ§‹é›‘ã«æ›¸ã“ã†ã¨æ€ã„ã¾ã™]ï¼
ã¨ã„ã†ã‹ï¼Œæœ‰è­˜è€…å„ä½èª°ã‹æ•™ãˆã¦ãã ã•ã„ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼

# DPC++ã¯C++ AMPã®å¤¢ã‚’è¦‹ã‚‹ã‹

æ˜¨å¹´ã‚‚è¨˜äº‹ã«ã—ã¾ã—ãŸãŒ[C++ AMPãŒæ­»ã«ã¾ã—ãŸ](https://zenn.dev/wx257osn2/articles/rip_cxx_amp-ksaudhawigubweinfwklaeiuhfawelifh)ï¼
å½“æ™‚ã®è¨˜äº‹ã«ã‚‚è¨˜è¼‰ã—ã¦ã„ã‚‹é€šã‚Šï¼Œ

- ã‚·ãƒ³ã‚°ãƒ«ã‚½ãƒ¼ã‚¹ã§
- æœ€æ–°ã®C++ã®è¨€èªæ©Ÿèƒ½ãŒä½¿ãˆã¦
- ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚¹APIã¨ã®interopãŒã‚ã‚Š
- ãƒ‡ãƒã‚¤ã‚¹éä¾å­˜ã§
- çªç„¶æ­»ãªãªã„

APIã‚’æ¢ã—æ±‚ã‚ã¦ã„ã‚‹^[å…·ä½“çš„ãªè¡Œå‹•ã¯ç‰¹ã«ã—ã¦ãªã„ï¼ã¨ã„ã†ã‹ã“ã®è¨˜äº‹ã‚’C++ AdCã®è¨˜äº‹ã¨ã™ã‚‹ã“ã¨ã§ç· åˆ‡é§†å‹•é€²æ—ã‚’ã‚„ã‚ã†ã¨ã—ãŸçµæœå¤±æ•—ã—ãŸ]ã‚ã‘ã§ã™ãŒï¼Œã‚„ã¯ã‚Šå…ˆã®è¨˜äº‹ã§ã‚‚è¿°ã¹ãŸé€šã‚ŠSYCLã‚’æœ¬å‘½ã«æ®ãˆã¦ã„ã‚‹ã‚ã‘ã§ã™ã­ï¼
ã¨ã„ã†ã‚ã‘ã§ï¼ŒSYCLã®1å®Ÿè£…ã§ã‚ã‚‹Intel oneAPI DPC++ãŒä¸Šè¨˜ã®ã‚ˆã†ãªæŒ¯ã‚‹èˆã„ã‚’ã§ãã‚‹ã®ã‹èª¿ã¹ã¦ã¿ã¾ã—ãŸ^[ã¨ã„ã†ã‚ã‘ã§è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã®ã€ŒC++ AMPã€ã¯ã€Œä¸Šè¨˜ã®ã‚ˆã†ãªæ€§è³ªã‚’æŒã£ãŸAPIã€ã®ã“ã¨ã‚’æŒ‡ã—ã¦ãŠã‚Šï¼ŒDPC++ã§C++ AMPã‚’æ›¸ã“ã†ï¼ã¨ã„ã†æ„å‘³ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ã‚ã—ã‹ã‚‰ãš]ï¼

## ã‚„ã‚ŠãŸã„ã“ã¨

`SYCL <-> ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰API <-> ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚¹API` ã®ã‚ˆã†ãªå½¢ã§ãã‚Œãã‚Œã®APIã‚’interopã—ï¼ŒSYCLã‹ã‚‰ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚¹APIã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å…¥å‡ºåŠ›ã¨ã—ãŸæ¼”ç®—ã‚’ã‹ã‘ã‚‹ã“ã¨ãŒç›®æ¨™ã§ã™ï¼
ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰API(CUDAã‚„OpenCLãªã©)ã¨ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚¹API(ã“ã“ã§ã¯DirectX)ã®interopã¯æ¦‚ã­å•é¡Œãªãå‹•ä½œã™ã‚‹ã¯ãšãªã®ã§ï¼ŒSYCLã¨ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰APIã®interopã«ã¤ã„ã¦èª¿ã¹ã¾ã™ï¼
å•é¡Œãªãå‹•ä½œã—ãŸã‚‰ã‚°ãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚¹APIã¨æ¥ç¶šã—ã¦ã¿ã¾ã™ï¼

### SYCLã¨ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®interop

SYCLã¯ğŸ†‘ã®åã‚’å† ã—ã¦ã„ã¾ã™ãŒï¼Œãã®å®Ÿãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«OpenCLã¯è¦æ±‚ã—ã¦ãŠã‚‰ãšï¼Œå®Ÿéš›ã«CUDAãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãªã©ã®å®Ÿè£…ãŒå­˜åœ¨ã—ã¾ã™ï¼
ãã®ãŸã‚SYCLã§ã¯ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ã®æ±ç”¨çš„ãªinterop APIãŒæä¾›ã•ã‚Œã¦ãŠã‚Šï¼Œã“ã‚Œã‚’ç”¨ã„ã‚‹ã“ã¨ã§SYCLã®ãƒªã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’æŠœãå‡ºã—ãŸã‚Šï¼Œé€†ã«ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®ãƒªã‚½ãƒ¼ã‚¹ã‹ã‚‰SYCLã®ãƒªã‚½ãƒ¼ã‚¹ã‚’ç”Ÿæˆã—ãŸã‚Šã§ãã‚‹ã‚ã‘ã§ã™ã­ï¼
DPC++ã¯OpenCLãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã®ã§ï¼Œ `sycl::make_ãªã‚“ã¨ã‹<cl::sycl::backend::opencl>(OpenCLã®ãƒªã‚½ãƒ¼ã‚¹)` ã¿ãŸã„ãªã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãã¨ã„ã„æ„Ÿã˜ã«OpenCLã®ãƒªã‚½ãƒ¼ã‚¹ã‚’SYCLã«æŒã¡è¾¼ã‚ã¾ã™ï¼
ã¨ã„ã†ã‚ã‘ã§ï¼Œä»¥ä¸‹ã®ã‚ˆã†ãªã‚³ãƒ¼ãƒ‰ã‚’ç”¨æ„ã—ã¾ã™ï¼

```cpp
#define CL_USE_DEPRECATED_OPENCL_1_2_APIS
#include<CL/sycl.hpp>
#include<CL/cl.h>
#include<stdexcept>
#include<memory>
#include<type_traits>
#include<vector>
#include<iostream>

auto create_cl_context(::cl_device_id device_id){
	cl_int ret;
	std::unique_ptr<std::remove_pointer_t<::cl_context>, decltype(&::clReleaseContext)> context = {::clCreateContext(nullptr, 1, &device_id, nullptr, nullptr, &ret), &::clReleaseContext};
	if(ret != CL_SUCCESS)
		throw std::runtime_error("create_cl_context failed");
	return context;
}

auto create_cl_command_queue(::cl_context context, ::cl_device_id device_id){
	cl_int ret;
	std::unique_ptr<std::remove_pointer_t<::cl_command_queue>, decltype(&::clReleaseCommandQueue)> queue = {::clCreateCommandQueue(context, device_id, 0, &ret), &::clReleaseCommandQueue};
	if(ret != CL_SUCCESS)
		throw std::runtime_error("create_cl_command_queue failed");
	return queue;
}

auto create_cl_buffer(::cl_context context, ::cl_mem_flags flags, std::size_t size){
	cl_int ret;
	std::unique_ptr<std::remove_pointer_t<::cl_mem>, decltype(&::clReleaseMemObject)> buffer = {::clCreateBuffer(context, flags, size, nullptr, &ret), &::clReleaseMemObject};
	if(ret != CL_SUCCESS)
		throw std::runtime_error("create_cl_buffer failed");
	return buffer;
}

void write_buffer(::cl_command_queue queue, ::cl_mem obj, std::size_t size, const void* ptr){
	if(::clEnqueueWriteBuffer(queue, obj, CL_TRUE, 0, size, ptr, 0, nullptr, nullptr) != CL_SUCCESS)
		throw std::runtime_error("write_buffer failed");
}

void read_buffer(::cl_command_queue queue, ::cl_mem obj, std::size_t size, void* ptr){
	if(::clEnqueueReadBuffer(queue, obj, CL_TRUE, 0, size, ptr, 0, nullptr, nullptr) != CL_SUCCESS)
		throw std::runtime_error("read_buffer failed");
}

int main()try{
	const auto device_id = /* ã“ã“ã«OpenCLã®ãƒ‡ãƒã‚¤ã‚¹ID */;
	auto device = sycl::make_device<cl::sycl::backend::opencl>(device_id);
	auto platform = device.get_platform();
	std::cout << platform.get_info<sycl::info::platform::name>() << std::endl;
	std::cout << device.get_info<sycl::info::device::name>() << std::endl;
	const auto cl_context = create_cl_context(device_id);
	auto context = sycl::make_context<cl::sycl::backend::opencl>(cl_context.get());
	const auto cl_queue = create_cl_command_queue(cl_context.get(), device_id);
	auto queue = sycl::make_queue<cl::sycl::backend::opencl>(cl_queue.get(), context);

	const std::vector<float> a(3, 42.f);
	const std::vector<float> b = {0.1f, 0.2f, 0.3f};
	std::vector<float> c(3);
	auto cl_a = create_cl_buffer(cl_context.get(), CL_MEM_READ_ONLY, sizeof(float) * a.size());
	auto cl_b = create_cl_buffer(cl_context.get(), CL_MEM_READ_ONLY, sizeof(float) * b.size());
	auto cl_c = create_cl_buffer(cl_context.get(), CL_MEM_WRITE_ONLY, sizeof(float) * c.size());
	write_buffer(cl_queue.get(), cl_a.get(), sizeof(float) * a.size(), a.data());
	write_buffer(cl_queue.get(), cl_b.get(), sizeof(float) * b.size(), b.data());
	auto ba = sycl::make_buffer<cl::sycl::backend::opencl, float, 1>(cl_a.get(), context);
	auto bb = sycl::make_buffer<cl::sycl::backend::opencl, float, 1>(cl_b.get(), context);
	auto bc = sycl::make_buffer<cl::sycl::backend::opencl, float, 1>(cl_c.get(), context);
	queue.submit([&](sycl::handler& cgh){
		auto acca = ba.get_access<sycl::access_mode::read>(cgh);
		auto accb = bb.get_access<sycl::access_mode::read>(cgh);
		auto accc = bc.get_access<sycl::access_mode::write>(cgh);
		cgh.parallel_for(sycl::range<1>{a.size()}, [=](auto idx){
			accc[idx] = acca[idx] + accb[idx];
		});
	});
	queue.wait();
	read_buffer(cl_queue.get(), cl_c.get(), sizeof(float) * c.size(), c.data());
	for(auto x : c)
		std::cout << x << std::endl;
}catch(const std::exception& e){
	std::cerr << "Exception: " << e.what() << std::endl;
}
```

ã§ï¼Œã‚ã¨ã¯ `device_id` å¤‰æ•°ã«é©å½“ãªãƒ‡ãƒã‚¤ã‚¹IDã‚’çªã£è¾¼ã‚€ã ã‘ã§ã™ã­ï¼
ã¾ãšã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒ å…¨ä½“ãŒæ­£ã—ãå‹•ãã“ã¨ã‚’ç¢ºèªã™ã‚‹ãŸã‚ã«ï¼ŒCPUã®ãƒ‡ãƒã‚¤ã‚¹IDã‚’çªã£è¾¼ã‚“ã§ã¿ã¾ã—ã‚‡ã†ï¼

![å®Ÿè¡Œçµæœ1](/images/does_dpcxx_dream_of_cxx_amp-oiansdlwiubg/01_sycl_on_cpu.png)

å•é¡Œãªã•ãã†ã§ã™ï¼ã§ã¯æ¬¡ã«ï¼ŒNVIDIA GPUã®ãƒ‡ãƒã‚¤ã‚¹IDã‚’çªã£è¾¼ã‚“ã§ã¿ã¾ã—ã‚‡ã†ï¼

![å®Ÿè¡Œçµæœ2](/images/does_dpcxx_dream_of_cxx_amp-oiansdlwiubg/02_sycl_on_gpu.png)

æ­»ã«ã¾ã—ãŸ^[å…·ä½“çš„ã«ã¯ `cgh.parallel_for` ã§ã‚«ãƒ¼ãƒãƒ«ç”Ÿæˆã—ã‚ˆã†ã¨ã—ãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã‚³ã‚±ã¾ã™ï¼æƒ³å®šã—ã¦ã„ãªã„OpenCLãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãŒæ¥ãŸã¿ãŸã„ãªé¡”ã—ã¦ã‚“ãª]ï¼

## ã¾ã¨ã‚

ã©ã†ã‚„ã‚‰ã“ã®æ–¹é‡ã§ã¯ä¸Šæ‰‹ãè¡Œã‹ãªã•ãã†ãªã®ã§ï¼Œä»¥ä¸‹ã®ã„ãšã‚Œã‹ã‚’è©¦ã™å¿…è¦ãŒã‚ã‚Šãã†ã§ã™ï¼

- ComputeCppã‚’è©¦ã™
    - ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œã‚‹ã®ã‚ã‚“ã©ãã›ã‡ã£ã¤ã£ã¦æ”¾ç½®ã—ã¦ã¾ã™
- DPC++ã®CUDAãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’æœ‰åŠ¹åŒ–ã—ã¦è©¦ã™
    - ç¾çŠ¶OpenCLã§NVIDIA GPUã‚’æ‰±ã†ã®ã¯ç„¡ç†ã£ã½ã„ã®ã§ï¼Œå¤§äººã—ãCUDAã‚µãƒãƒ¼ãƒˆã«ä¹—ã£ã‹ã‚‹
        - ãƒ‡ãƒã‚¤ã‚¹ã«ä¾å­˜ã—ã¡ã‚ƒã†ã‘ã©ã¾ãè‡´ã—æ–¹ãªã—â€¦interopã®éƒ¨åˆ†ã•ãˆç½®ãæ›ãˆã¦ã‚„ã‚Œã°ä»–ã¯ä½¿ã„ã¾ã‚ã›ã‚‹ã—å¤šå°‘ã¯ã­ï¼Ÿ
        - ã¡ãªã¿ã«ä½•æ•…NVIDIA GPUã‚’æ‰±ãˆãªã„ã®ã‹ã«ã¤ã„ã¦ã¯ï¼Œã‚‚ã—ã‹ã™ã‚‹ã¨CUDAã®OpenCLãŒæœªã ã«1.2ãªã®ãŒæ‚ªã„ã‹ã‚‚ã—ã‚Œãªã„ï¼Ÿ(çœŸé¢ç›®ã«èª¿æŸ»ã—ã¦ãªã„ã®ã§ã‚ã‹ã‚‰ãš)
    - ã¨ã“ã‚ã§[CUDAãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¯ç¾çŠ¶Linuxã§ã—ã‹ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„](https://intel.github.io/llvm-docs/GetStartedGuide.html#cuda-back-end-limitations)â€¦ã¨ã„ã†è¨˜è¿°ã¨ï¼Œ[ã‚µãƒãƒ¼ãƒˆã—ã¨ã‚‹ã§](https://intel.github.io/llvm-docs/GetStartedGuide.html#build-dpc-toolchain-with-support-for-nvidia-cuda)ã¨ã„ã†è¨˜è¿°ãŒã‚ã‚‹ï¼ã©ã£ã¡ã‚„ã­ã‚“
        - > Backend is only supported on Linux
        - > Note, the CUDA backend has Windows support; windows subsystem for linux (WSL) is not needed to build and run the CUDA backend.
    - ã—ï¼Œ[è‡ªå‰ã®ãƒ“ãƒ«ãƒ‰ãŒå¿…è¦](https://intel.github.io/llvm-docs/GetStartedGuide.html#build-dpc-toolchain-with-support-for-nvidia-cuda) ãˆï¼ŒWindowsã§ã“ã‚Œã‚„ã‚“ã®ã¾ã˜ï¼Ÿã‚ã‚“ã©ãã•ããªã„ï¼Ÿ

**OpenCLãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã§ã‚ˆã—ãªã«ã‚„ã‚‹æ–¹æ³•ï¼Œã‚ã‚‹ã„ã¯ãªã‚“ã§CUDAã®OpenCLãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã ã¨ã‚³ã‚±ã‚‹ã®ã‹ã”å­˜ã˜ã®æ–¹ãŒã„ã‚‰ã£ã—ã‚ƒã„ã¾ã—ãŸã‚‰æ˜¯éã”æ•™ç¤ºãŠé¡˜ã„ã—ã¾ã™**^[ã“ã‚Œã®ãŸã‚ã«è¨˜äº‹æ›¸ã„ãŸï¼ãŸã™ã‘ã¦]ï¼

ã¨ã„ã†ã‚ã‘ã§ï¼Œæ¬¡å›^[_ã„ã¤ï¼Ÿ_]ï¼ŒDPC++ã‚’ãƒ“ãƒ«ãƒ‰ã—ã¦CUDAãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’è©¦ã™ï¼ **ä¿ºé”ã®æº€è¶³ã¯ï¼Œã“ã‚Œã‹ã‚‰ã ï¼ï¼** ^[ã¨ã„ã†æ®‹å¿µãªçµæœã«çµ‚ã‚ã£ãŸã®ã§ï¼Œã“ã‚ŒãŒAdCã®è¨˜äº‹ã£ã¦ã®ã‚‚ãªãâ€¦ã¨ãªã‚Š[20æ—¥ç›®ã®è¨˜äº‹ã‚’æ›¸ãã«è‡³ã‚‹](https://zenn.dev/wx257osn2/articles/constexpr_variant-jdbnlwiberawejbf)]